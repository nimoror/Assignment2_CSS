{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15be93b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "077b6df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>citationCount</th>\n",
       "      <th>externalIds.DOI</th>\n",
       "      <th>keywords</th>\n",
       "      <th>authorIds</th>\n",
       "      <th>author_fields</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1733874</th>\n",
       "      <td>29e01b2f3beacd67033d3c4d90cc2fa2e3f80801</td>\n",
       "      <td>FRAGEN</td>\n",
       "      <td>1708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1007/978-3-531-19901-6_4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[46564370]</td>\n",
       "      <td>[Economics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136477</th>\n",
       "      <td>43bba6631b3d74d34d5942c2cab71409a1b9f8ce</td>\n",
       "      <td>FAUST</td>\n",
       "      <td>1791</td>\n",
       "      <td>63.0</td>\n",
       "      <td>10.1007/978-3-476-99297-0_8</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2052703034]</td>\n",
       "      <td>[Linguistics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124537</th>\n",
       "      <td>45214c57d7e67dbc08c21472b912c05dff30421e</td>\n",
       "      <td>Errata</td>\n",
       "      <td>1799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1177/00220345770560042001</td>\n",
       "      <td>[Biology]</td>\n",
       "      <td>[5629680]</td>\n",
       "      <td>[Medicine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754206</th>\n",
       "      <td>5ddcc9eff9c4f8e559d83457366b15e13b5f0e78</td>\n",
       "      <td>XXI. Description of a large Species of Rat, a ...</td>\n",
       "      <td>1804</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1111/J.1096-3642.1804.TB00297.X</td>\n",
       "      <td>[]</td>\n",
       "      <td>[5035526]</td>\n",
       "      <td>[Psychology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13387</th>\n",
       "      <td>6762672c44e030c8754b7676197a0a645e923b74</td>\n",
       "      <td>Book Reviews</td>\n",
       "      <td>1805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1007/s12138-003-0005-1</td>\n",
       "      <td>[Education]</td>\n",
       "      <td>[52356613]</td>\n",
       "      <td>[History]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642454</th>\n",
       "      <td>ed4f2dc3d9a9dbe4edc6af33c64b85301288f424</td>\n",
       "      <td>Assessment of oppositional defiant disorder an...</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.3389/fpsyt.2022.1062201</td>\n",
       "      <td>[Psychology, Medicine]</td>\n",
       "      <td>[35123009]</td>\n",
       "      <td>[Medicine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644388</th>\n",
       "      <td>16cd6653f741db540f4d9daa525ca1deff2132ae</td>\n",
       "      <td>Revisiting Cellular Throughput Prediction: Lea...</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[1708109]</td>\n",
       "      <td>[Computer Science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644389</th>\n",
       "      <td>b856f7f55a1dbae5e9ef0e52c801b3ff5126a5f9</td>\n",
       "      <td>Self-medication practices with antibiotics amo...</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.3126/ajms.v14i1.47836</td>\n",
       "      <td>[Medicine]</td>\n",
       "      <td>[1708109]</td>\n",
       "      <td>[Computer Science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644859</th>\n",
       "      <td>c84efe86ae773619c49d18e1212b98de334e0282</td>\n",
       "      <td>Spatial transcriptomics analysis of neoadjuvan...</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1101/2023.01.10.523481</td>\n",
       "      <td>[Biology, Medicine]</td>\n",
       "      <td>[5962503]</td>\n",
       "      <td>[Biology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645394</th>\n",
       "      <td>9e2e4342dabd9bf903237644a74599e1c423e912</td>\n",
       "      <td>Planetary health literacy: A conceptual model</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.3389/fpubh.2022.980779</td>\n",
       "      <td>[Physics, Education]</td>\n",
       "      <td>[10745935]</td>\n",
       "      <td>[Economics]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2638387 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          paperId  \\\n",
       "1733874  29e01b2f3beacd67033d3c4d90cc2fa2e3f80801   \n",
       "2136477  43bba6631b3d74d34d5942c2cab71409a1b9f8ce   \n",
       "2124537  45214c57d7e67dbc08c21472b912c05dff30421e   \n",
       "754206   5ddcc9eff9c4f8e559d83457366b15e13b5f0e78   \n",
       "13387    6762672c44e030c8754b7676197a0a645e923b74   \n",
       "...                                           ...   \n",
       "2642454  ed4f2dc3d9a9dbe4edc6af33c64b85301288f424   \n",
       "2644388  16cd6653f741db540f4d9daa525ca1deff2132ae   \n",
       "2644389  b856f7f55a1dbae5e9ef0e52c801b3ff5126a5f9   \n",
       "2644859  c84efe86ae773619c49d18e1212b98de334e0282   \n",
       "2645394  9e2e4342dabd9bf903237644a74599e1c423e912   \n",
       "\n",
       "                                                     title  year  \\\n",
       "1733874                                             FRAGEN  1708   \n",
       "2136477                                              FAUST  1791   \n",
       "2124537                                             Errata  1799   \n",
       "754206   XXI. Description of a large Species of Rat, a ...  1804   \n",
       "13387                                         Book Reviews  1805   \n",
       "...                                                    ...   ...   \n",
       "2642454  Assessment of oppositional defiant disorder an...  2023   \n",
       "2644388  Revisiting Cellular Throughput Prediction: Lea...  2023   \n",
       "2644389  Self-medication practices with antibiotics amo...  2023   \n",
       "2644859  Spatial transcriptomics analysis of neoadjuvan...  2023   \n",
       "2645394      Planetary health literacy: A conceptual model  2023   \n",
       "\n",
       "         citationCount                     externalIds.DOI  \\\n",
       "1733874            0.0         10.1007/978-3-531-19901-6_4   \n",
       "2136477           63.0         10.1007/978-3-476-99297-0_8   \n",
       "2124537            0.0        10.1177/00220345770560042001   \n",
       "754206             1.0  10.1111/J.1096-3642.1804.TB00297.X   \n",
       "13387              0.0           10.1007/s12138-003-0005-1   \n",
       "...                ...                                 ...   \n",
       "2642454            0.0          10.3389/fpsyt.2022.1062201   \n",
       "2644388            0.0                                 NaN   \n",
       "2644389            0.0            10.3126/ajms.v14i1.47836   \n",
       "2644859            0.0           10.1101/2023.01.10.523481   \n",
       "2645394            0.0           10.3389/fpubh.2022.980779   \n",
       "\n",
       "                       keywords     authorIds       author_fields  \n",
       "1733874                      []    [46564370]         [Economics]  \n",
       "2136477                      []  [2052703034]       [Linguistics]  \n",
       "2124537               [Biology]     [5629680]          [Medicine]  \n",
       "754206                       []     [5035526]        [Psychology]  \n",
       "13387               [Education]    [52356613]           [History]  \n",
       "...                         ...           ...                 ...  \n",
       "2642454  [Psychology, Medicine]    [35123009]          [Medicine]  \n",
       "2644388      [Computer Science]     [1708109]  [Computer Science]  \n",
       "2644389              [Medicine]     [1708109]  [Computer Science]  \n",
       "2644859     [Biology, Medicine]     [5962503]           [Biology]  \n",
       "2645394    [Physics, Education]    [10745935]         [Economics]  \n",
       "\n",
       "[2638387 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_data():\n",
    "    init = pd.read_pickle(os.path.join(os.getcwd(),\"paper_subset/1708.pkl\"))\n",
    "    final = pd.DataFrame(columns=init.keys())\n",
    "    files = os.listdir(os.path.join(os.getcwd(),'paper_subset'))\n",
    "    for file in files[1:]:\n",
    "        if file.endswith(\".pkl\"):\n",
    "            temp = pd.read_pickle(os.path.join(os.getcwd(),'paper_subset/'+file))\n",
    "            final = pd.concat([final, temp])\n",
    "    return final\n",
    "    \n",
    "papers_df = make_data()\n",
    "papers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0afcd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>citationCount</th>\n",
       "      <th>externalIds.DOI</th>\n",
       "      <th>keywords</th>\n",
       "      <th>authorIds</th>\n",
       "      <th>author_fields</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>b30d4b44131698820ed05bcf7fb62c8fc6201672</td>\n",
       "      <td>Developing recommendations for designing smart...</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Computer Science, Sociology]</td>\n",
       "      <td>[1788563]</td>\n",
       "      <td>[Computer Science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>9d59892c5657098bd3825116af8fad8d8ee943ff</td>\n",
       "      <td>Group Fairness for Indivisible Goods Allocation</td>\n",
       "      <td>2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Economics, Computer Science]</td>\n",
       "      <td>[1749906, 4006636]</td>\n",
       "      <td>[Economics, Computer Science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27944</th>\n",
       "      <td>867cc74781225da4e08a77fc35037ba77911e455</td>\n",
       "      <td>Hindsight Credit Assignment</td>\n",
       "      <td>2019</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Economics, Computer Science]</td>\n",
       "      <td>[37666967, 144368601, 2605877, 3134710]</td>\n",
       "      <td>[Computer Science, Computer Science, Computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31824</th>\n",
       "      <td>37a0f28f6aa41028e64d0440001ff525d67c1305</td>\n",
       "      <td>The Constrained Round Robin Algorithm for Fair...</td>\n",
       "      <td>2019</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Economics, Computer Science]</td>\n",
       "      <td>[144433798, 143999398]</td>\n",
       "      <td>[Economics, Computer Science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83205</th>\n",
       "      <td>894b376090e1e843c79211603814ccbcab09f632</td>\n",
       "      <td>Interpretable Almost Matching Exactly With Ins...</td>\n",
       "      <td>2019</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Economics, Computer Science]</td>\n",
       "      <td>[31938009, 48395540, 6974508]</td>\n",
       "      <td>[Computer Science, Computer Science, Computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391796</th>\n",
       "      <td>3cbdec1b14b23320f175ac0f4936871d96fa9f07</td>\n",
       "      <td>The Keyword Explorer Suite: A Toolkit for Unde...</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Economics, Education, Computer Science]</td>\n",
       "      <td>[40289577]</td>\n",
       "      <td>[Computer Science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080886</th>\n",
       "      <td>12e93d2094d51acedb43727dacfe9da355f5d10f</td>\n",
       "      <td>Using citation networks to evaluate the impact...</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Economics, Education, Computer Science]</td>\n",
       "      <td>[3161628, 143975462]</td>\n",
       "      <td>[Computer Science, Computer Science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795582</th>\n",
       "      <td>6348ea334196587c419b0cfc6b6bae11679b02eb</td>\n",
       "      <td>Cryptocurrency co-investment network: token re...</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Economics]</td>\n",
       "      <td>[2818774]</td>\n",
       "      <td>[Computer Science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471693</th>\n",
       "      <td>08a51de6f966f298baf711b80b00fc5701aa663c</td>\n",
       "      <td>#EndSARS Protest: Discourse and Mobilisation o...</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Political Science]</td>\n",
       "      <td>[52143529]</td>\n",
       "      <td>[Computer Science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553238</th>\n",
       "      <td>9ab611afc6e5d26fb06d1298df4a4441489407a5</td>\n",
       "      <td>Statistical analysis of word flow among five I...</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Economics]</td>\n",
       "      <td>[1745123]</td>\n",
       "      <td>[Computer Science]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1448 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          paperId  \\\n",
       "442      b30d4b44131698820ed05bcf7fb62c8fc6201672   \n",
       "2964     9d59892c5657098bd3825116af8fad8d8ee943ff   \n",
       "27944    867cc74781225da4e08a77fc35037ba77911e455   \n",
       "31824    37a0f28f6aa41028e64d0440001ff525d67c1305   \n",
       "83205    894b376090e1e843c79211603814ccbcab09f632   \n",
       "...                                           ...   \n",
       "391796   3cbdec1b14b23320f175ac0f4936871d96fa9f07   \n",
       "1080886  12e93d2094d51acedb43727dacfe9da355f5d10f   \n",
       "1795582  6348ea334196587c419b0cfc6b6bae11679b02eb   \n",
       "2471693  08a51de6f966f298baf711b80b00fc5701aa663c   \n",
       "2553238  9ab611afc6e5d26fb06d1298df4a4441489407a5   \n",
       "\n",
       "                                                     title  year  \\\n",
       "442      Developing recommendations for designing smart...  2019   \n",
       "2964       Group Fairness for Indivisible Goods Allocation  2019   \n",
       "27944                          Hindsight Credit Assignment  2019   \n",
       "31824    The Constrained Round Robin Algorithm for Fair...  2019   \n",
       "83205    Interpretable Almost Matching Exactly With Ins...  2019   \n",
       "...                                                    ...   ...   \n",
       "391796   The Keyword Explorer Suite: A Toolkit for Unde...  2023   \n",
       "1080886  Using citation networks to evaluate the impact...  2023   \n",
       "1795582  Cryptocurrency co-investment network: token re...  2023   \n",
       "2471693  #EndSARS Protest: Discourse and Mobilisation o...  2023   \n",
       "2553238  Statistical analysis of word flow among five I...  2023   \n",
       "\n",
       "         citationCount externalIds.DOI  \\\n",
       "442                1.0             NaN   \n",
       "2964               4.0             NaN   \n",
       "27944             37.0             NaN   \n",
       "31824              9.0             NaN   \n",
       "83205              5.0             NaN   \n",
       "...                ...             ...   \n",
       "391796             0.0             NaN   \n",
       "1080886            0.0             NaN   \n",
       "1795582            0.0             NaN   \n",
       "2471693            0.0             NaN   \n",
       "2553238            0.0             NaN   \n",
       "\n",
       "                                         keywords  \\\n",
       "442                 [Computer Science, Sociology]   \n",
       "2964                [Economics, Computer Science]   \n",
       "27944               [Economics, Computer Science]   \n",
       "31824               [Economics, Computer Science]   \n",
       "83205               [Economics, Computer Science]   \n",
       "...                                           ...   \n",
       "391796   [Economics, Education, Computer Science]   \n",
       "1080886  [Economics, Education, Computer Science]   \n",
       "1795582                               [Economics]   \n",
       "2471693                       [Political Science]   \n",
       "2553238                               [Economics]   \n",
       "\n",
       "                                       authorIds  \\\n",
       "442                                    [1788563]   \n",
       "2964                          [1749906, 4006636]   \n",
       "27944    [37666967, 144368601, 2605877, 3134710]   \n",
       "31824                     [144433798, 143999398]   \n",
       "83205              [31938009, 48395540, 6974508]   \n",
       "...                                          ...   \n",
       "391796                                [40289577]   \n",
       "1080886                     [3161628, 143975462]   \n",
       "1795582                                [2818774]   \n",
       "2471693                               [52143529]   \n",
       "2553238                                [1745123]   \n",
       "\n",
       "                                             author_fields  \n",
       "442                                     [Computer Science]  \n",
       "2964                         [Economics, Computer Science]  \n",
       "27944    [Computer Science, Computer Science, Computer ...  \n",
       "31824                        [Economics, Computer Science]  \n",
       "83205    [Computer Science, Computer Science, Computer ...  \n",
       "...                                                    ...  \n",
       "391796                                  [Computer Science]  \n",
       "1080886               [Computer Science, Computer Science]  \n",
       "1795582                                 [Computer Science]  \n",
       "2471693                                 [Computer Science]  \n",
       "2553238                                 [Computer Science]  \n",
       "\n",
       "[1448 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSS_fields = ('Political Science', 'Sociology', 'Economics')\n",
    "quantitative_fields = ('Mathematics', 'Physics', 'Computer Science')\n",
    "\n",
    "papers_df = papers_df[papers_df['keywords'].apply(lambda x: any(field in x for field in CSS_fields))]\n",
    "Quant_df1 = papers_df[papers_df['keywords'].apply(lambda x: any(field in x for field in quantitative_fields))]\n",
    "Quant_df2 = papers_df[papers_df['author_fields'].apply(lambda x: any(field in x for field in quantitative_fields))]\n",
    "papers_df = pd.concat([Quant_df1,Quant_df2])\n",
    "papers_df = papers_df[papers_df['keywords'].apply(lambda x: 'Biology' not in x)]\n",
    "papers_df = papers_df[papers_df['authorIds'].apply(lambda x: len(x)) < 10]\n",
    "papers_df = papers_df[papers_df['year'].apply(lambda x: x > 2018)]\n",
    "papers_df = papers_df[papers_df['externalIds.DOI'].isna()]\n",
    "ccs_papers = papers_df\n",
    "ccs_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2469fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CSS_subset(df):\n",
    "\n",
    "    subset_df = papers_df[papers_df['authorIds'].apply(lambda x: social_science_fields[0] in x)]\n",
    "\n",
    "\n",
    "    # flatten the 'authors' column into a list of all authors\n",
    "    author_fields = [field for field_list in subset_df['author_fields'] for field in field_list]\n",
    "\n",
    "    # count the frequency of each author using the Counter class\n",
    "    freq_fields = Counter(author_fields)\n",
    "\n",
    "    # get the most common field\n",
    "    most_common_field = freq_fields.most_common(1)[0][0]\n",
    "    print(2638387)\n",
    "    return most_common_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee6c5d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'most_freq_field' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmost_freq_field\u001b[49m(\u001b[38;5;241m10745935\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'most_freq_field' is not defined"
     ]
    }
   ],
   "source": [
    "most_freq_field(10745935)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a31cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_unique = list(set([field for field_list in papers_df['authorIds'] for field in field_list]))[0:100]\n",
    "authors_fields = [most_freq_field(author_id) for author_id in authors_unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e8425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of unique authors in the css_papers df:\n",
    "unique_authors = ccs_papers['authorIds'].explode().unique()\n",
    "len(unique_authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cbc05b",
   "metadata": {},
   "source": [
    "### Exercise 2: CSS Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8018695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "# create list of all unique name combinations\n",
    "name_combinations = []\n",
    "for names in ccs_papers['authorIds']:\n",
    "    name_combinations.extend(list(combinations(names, 2)))\n",
    "unique_combinations = list(set(name_combinations))\n",
    "\n",
    "# count occurrences of each unique name combination\n",
    "name_counts = Counter(name_combinations)\n",
    "\n",
    "# create final dataframe\n",
    "result_df = pd.DataFrame({'Name 1': [c[0] for c in unique_combinations],\n",
    "                          'Name 2': [c[1] for c in unique_combinations],\n",
    "                          'Count': [name_counts[c] for c in unique_combinations]})\n",
    "#result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d8079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = list(result_df.to_records(index=False))\n",
    "#edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb23c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_weighted_edges_from(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors = pd.read_pickle(os.path.join(os.getcwd(),'author_subset.pkl'))\n",
    "df_authors\n",
    "\n",
    "#create new column with longest alias:\n",
    "#df_authors['longest_alias'] = df_authors['aliases'].apply(lambda x: max(x, key=len)) \n",
    "\n",
    "#create new column with longest alias, while ignoring None type values:\n",
    "#df_authors['longest_alias'] = df_authors['aliases'].apply(lambda x: max([name for name in x if name is not None], key=len) if x else None)\n",
    "\n",
    "#Here it starts to get tricky to interpret what's happening but it works. Create new column with longest alias, while ignoring None type values. If the values are none, take name in the name column:\n",
    "df_authors['longest_alias'] = df_authors.apply(lambda row: max([name for name in row['aliases'] if name is not None], key=len) if row['aliases'] else row.at['name'], axis=1)\n",
    "\n",
    "df_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef41242",
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_dict = dict(zip(df_authors['authorId'], df_authors['longest_alias']))\n",
    "top_field_dict = dict(zip(df_authors['authorId'], df_authors['top_field']))\n",
    "\n",
    "nx.set_node_attributes(G, alias_dict, 'name')\n",
    "nx.set_node_attributes(G, top_field_dict, 'top_field')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21259abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe for Exercise 2.3. \n",
    "# Explode list column into separate rows\n",
    "df_exploded = ccs_papers.explode('authorIds')\n",
    "\n",
    "# Calculate mean, min, and max for each integer\n",
    "new_df = df_exploded.groupby('authorIds')['year'].agg(['min', 'size']).reset_index()\n",
    "new_df['medianCitationCount'] = df_exploded.groupby('authorIds')['citationCount'].agg(['median']).reset_index()['median']\n",
    "new_df['totalCitationCount'] = df_exploded.groupby('authorIds')['citationCount'].agg(['sum']).reset_index()['sum']\n",
    "\n",
    "new_df = new_df.rename({'min': 'firstPubl', 'size': 'numbPubl'}, axis=1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27386fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstPubl_dict = dict(zip(new_df['authorIds'], new_df['firstPubl']))\n",
    "numbPubl_dict = dict(zip(new_df['authorIds'], new_df['numbPubl']))\n",
    "medianCitationCount_dict = dict(zip(new_df['authorIds'], new_df['medianCitationCount']))\n",
    "TotalCitationCount_dict = dict(zip(new_df['authorIds'], new_df['totalCitationCount']))\n",
    "\n",
    "\n",
    "nx.set_node_attributes(G, firstPubl_dict, 'first_publication_year')\n",
    "nx.set_node_attributes(G, numbPubl_dict, 'number_of_publications')\n",
    "nx.set_node_attributes(G, medianCitationCount_dict, 'median_citation_count')\n",
    "nx.set_node_attributes(G, TotalCitationCount_dict, 'total_citation_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48726eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some commands to inspect the created graph\n",
    "#list(G.nodes)\n",
    "#list(G.edges)\n",
    "#G.degree['2124257085']\n",
    "#print(G.nodes['2076751932']['name'])  #no name was assigned as the author was likely not in the author dataframe\n",
    "print(G.nodes['2798221']['name'] + ', ' + G.nodes['2798221']['top_field']) #name was assigned instead of alias\n",
    "print(G.nodes['51428797']['name'] + ', ' + G.nodes['51428797']['top_field']) \n",
    "print(G.nodes['51428797']['first_publication_year'])\n",
    "print(G.nodes['51428797']['number_of_publications'])\n",
    "print(str(G.nodes['51428797']['median_citation_count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e359434",
   "metadata": {},
   "source": [
    "## Part 4: Preliminary analysis of the Computational Social Scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b58343",
   "metadata": {},
   "source": [
    "1. Why do you think I want you guys to use an undirected graph? Could have we used an directed graph instead?\n",
    "\n",
    "Authors that work together is inherently an undirected relationship. It's hard to imagine a use-case for directed graphs in this context.\n",
    "\n",
    "2. What is the total number of nodes in the network? What is the total number of links? What is the density of the network (that is the total number of links over the maximum number of links)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ae61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of nodes: ' + str(len(list(G.nodes))))\n",
    "print('number of edges: ' + str(len(list(G.edges))))\n",
    "density = nx.density(G)\n",
    "print('density of the network: ' + str(density))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d128e5cd",
   "metadata": {},
   "source": [
    "3. What are the average, median, mode, minimum and maximum value of the degree? What are the average, median, mode, minimum and maximum value of the nodes strength? How do you intepret the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ece52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute degree for each node\n",
    "degrees = list(dict(nx.degree(G)).values())\n",
    "\n",
    "# compute strength for each node\n",
    "strengths = list(dict(nx.degree(G, weight='weight')).values())\n",
    "\n",
    "# compute and print statistics for degrees\n",
    "print(\"Degree statistics:\")\n",
    "print(\"Mean: \", np.mean(degrees))\n",
    "print(\"Median: \", np.median(degrees))\n",
    "print(\"Mode: \", stats.mode(degrees)[0][0])\n",
    "print(\"Minimum: \", np.min(degrees))\n",
    "print(\"Maximum: \", np.max(degrees))\n",
    "\n",
    "# compute and print statistics for strengths\n",
    "print(\"Strength statistics:\")\n",
    "print(\"Mean: \", np.mean(strengths))\n",
    "print(\"Median: \", np.median(strengths))\n",
    "print(\"Mode: \", stats.mode(strengths)[0][0])\n",
    "print(\"Minimum: \", np.min(strengths))\n",
    "print(\"Maximum: \", np.max(strengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603311f8",
   "metadata": {},
   "source": [
    "On average an author has published papers with approx. 3 other authors in the database. Given that the median of the degrees is close to the mean, it seems that there are not that many authors that collaborated with extreme amounts of authors. Therefore, not as heavy-tailed as what we have seen in previous weeks.\n",
    "\n",
    "In undirected graphs, the strength can be calculated as the sum of the connectivity weights of the edges attached to each node. Given that many author collaborations lead to more than just one publication, these statistic values for strength are all higher than the ones for the degree (as minimum weight = 1). The authors in our dataset have on average collaborated with other authors on 6.5 papers. The median remained the same. Probably given that most authors only are represented by one paper in our dataset. Thus they only had one collaboration. The mean and median of the distribution of the strength are a bit further appart, indicating that the distribution became slightly more heavy tailed. When the number of publications between each collaboration is taken into account, the \"experienced\" authors that publish a lot influence the mean more significantly.\n",
    "\n",
    "\n",
    "4. List the top 5 authors by degree. What is their total number of citations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b08043",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_nodes = sorted(G, key=G.degree, reverse=True)[:5]\n",
    "print(top_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_sum = sum([G.nodes[node][\"total_citation_count\"] for node in top_nodes])\n",
    "print(\"Sum of citationCounts of top nodes:\", citation_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join([f\"Node {node} {'name'}: {G.nodes[node]['name']}\" for node in top_nodes]))\n",
    "#print('\\n'.join([f\"{G.nodes[node]['name']}\" for node in top_nodes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec4ffc4",
   "metadata": {},
   "source": [
    "5. Look them up online. What do they work on?\n",
    "\n",
    "Iyad Rahwan: An Associate Professor at MIT Media Lab, Rahwan's research focuses on artificial intelligence, machine learning, multi-agent systems, and computational social science. His work aims to understand and address the social and ethical implications of autonomous systems and artificial intelligence.\n",
    "\n",
    "Manlio De Domenico: A physicist and computer scientist, De Domenico's research interests include network science, computational social science, and data-driven modeling of complex systems. He works on developing mathematical and computational tools to study complex networks and their dynamics, and applies them to various areas, such as social networks, transportation systems, and biological networks.\n",
    "\n",
    "Andrea Baronchelli: A physicist and network scientist, Baronchelli's research focuses on understanding the structure and dynamics of complex networks, such as social networks, transportation networks, and biological networks. He develops mathematical and computational models to study these networks and their behavior, with the aim of uncovering fundamental principles that govern complex systems.\n",
    "\n",
    "Guillaume Cabanac: An information scientist, Cabanac's research interests include bibliometrics, scientometrics, and information retrieval. He works on developing algorithms and tools to analyze scientific publications and their impact, with the aim of improving the quality and efficiency of scientific research. His work also explores the social and ethical implications of the use of bibliometric indicators in scientific evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3c449f",
   "metadata": {},
   "source": [
    "6. Plot the distribution of degrees, using appropriate binning. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4783c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import math\n",
    "def setup_mpl():\n",
    "    #mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "    mpl.rcParams['font.size'] = 11\n",
    "    mpl.rcParams['figure.figsize'] = (7,2.5)\n",
    "    mpl.rcParams['figure.dpi'] = 300\n",
    "    \n",
    "setup_mpl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b25c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = degrees\n",
    "x_log = False\n",
    "y_log = False\n",
    "bar_hist = True\n",
    "\n",
    "# Create histogram\n",
    "bins = np.linspace(math.floor(min(X)), math.ceil(max(X)), math.ceil(max(X)))\n",
    "if x_log:\n",
    "    bins = np.logspace(0, np.log10(math.ceil(max(X))), math.ceil(max(X)))\n",
    "hist, edges = np.histogram(X, bins = bins, density = True) #change density to false if you want y = count (instead of probability distribution))\n",
    "x = (edges[1:]+edges[:-1])/2\n",
    "width = bins[1]-bins[0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "if bar_hist:\n",
    "    ax.bar(x, hist, width = width *0.9)\n",
    "else:\n",
    "    ax.plot(x, hist, marker = '.')\n",
    "\n",
    "ax.set_xlabel('Degrees')\n",
    "ax.set_ylabel('Probability distribution')\n",
    "if x_log:\n",
    "    ax.set_xscale('log')\n",
    "if y_log:\n",
    "    ax.set_yscale('log')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b3b3c",
   "metadata": {},
   "source": [
    "7. Plot a scatter plot of the the degree versus the \"median number of citations\" per ccs paper for all authors. Use logarithmic axes where appropriate. Compute the spearman correlation between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f21e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [G.nodes[node]['median_citation_count'] for node in G.nodes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11bd211",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the scatterplot\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X, Y, s=50, alpha=0.5, edgecolors='none')\n",
    "\n",
    "fig.set_figheight(3.5)\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "ax.set_xlabel('Degree (number of authors with whom collaborated)')\n",
    "ax.set_ylabel('Median citation count')\n",
    "\n",
    "# Customize the tick labels\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "# Customize the plot grid\n",
    "ax.grid(True, which='both', color='lightgrey', alpha=0.15) \n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f877051",
   "metadata": {},
   "source": [
    "8. Bin your degrees using the bins in point 6. and compute the 25th, 50th, and 75th percentile in each bin. Add the result to your figure as a line plot with errorbars (the median value is the line plot, and the 25th and 75th percentiles are the errorbars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a4aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = degrees\n",
    "x_log = False\n",
    "y_log = False\n",
    "bar_hist = True\n",
    "\n",
    "# Create histogram\n",
    "bins = np.linspace(math.floor(min(X))-0.5, math.ceil(max(X))-0.5, math.ceil(max(X))) # creates bins, shifted by 0.5 to have them centered on integer numbers (so we don't have 1.2 degrees, etc.)\n",
    "if x_log:\n",
    "    bins = np.logspace(0, np.log10(math.ceil(max(X))), math.ceil(max(X)))\n",
    "hist, edges = np.histogram(X, bins = bins, density = True) #change density to false if you want y = count (instead of probability distribution))\n",
    "x = (edges[1:]+edges[:-1])/2\n",
    "width = bins[1]-bins[0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "if bar_hist:\n",
    "    barplot = ax.bar(x, hist, width = width *0.9, label='Probability distribution')\n",
    "else:\n",
    "    ax.plot(x, hist, marker = '.')\n",
    "\n",
    "ax.set_xlabel('Degrees')\n",
    "ax.set_ylabel('Probability distribution')\n",
    "if x_log:\n",
    "    ax.set_xscale('log')\n",
    "if y_log:\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "lineplot = plt.plot(bins[:-1] + 0.5, hist, color='black', linewidth=0.6, label='Median')\n",
    "\n",
    "\"\"\"\n",
    "# calculate percentiles for each bin\n",
    "pct25 = []\n",
    "pct75 = []\n",
    "X_arr = np.array(X) # Convert lists to NumPy arrays\n",
    "Y_arr = np.array(Y) # Convert lists to NumPy arrays\n",
    "for i in range(len(bins)-1):\n",
    "    bin_data = Y_arr[(X_arr >= bins[i]) & (X_arr < bins[i+1])]\n",
    "    try:\n",
    "        pct25.append(np.percentile(bin_data, 25))\n",
    "        pct75.append(np.percentile(bin_data, 75))\n",
    "    except:\n",
    "        pct25.append(0)\n",
    "        pct75.append(0)\n",
    "        \n",
    "pct25 = [x / 2 for x in pct25]\n",
    "pct75 = [x / 2 for x in pct75]\n",
    "\n",
    "pct25_diff = hist - pct25\n",
    "pct75_diff = pct75-hist\n",
    "errorbar = plt.errorbar(x = bins[:-1] + 0.5, y=hist, yerr=np.vstack((pct25_diff, pct75_diff)), color='black', capsize= 3, capthick=0.75, elinewidth=0.75, label='Median and 25 and 75th percentile')\n",
    "\n",
    "handles = [barplot, errorbar]\n",
    "labels = [h.get_label() for h in handles]\n",
    "ax.legend(handles, labels, loc='upper right')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573700c1",
   "metadata": {},
   "source": [
    "9. Why do you think I wanted you guys to use the Spearman correlation (instead of the usual Pearson correlation)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525ec5ac",
   "metadata": {},
   "source": [
    "10. Comment on your results. Do you observe any relation? If yes, what could be the underlying reason, and how could you further explore possible reasons? If not, why do you think that is the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd57f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save graph for using it in week 5\n",
    "nx.write_gpickle(G, \"css_graph.gpickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
