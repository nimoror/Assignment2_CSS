{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b17dd83",
   "metadata": {},
   "source": [
    "link to github: https://github.com/nimoror/Assignment2_CSS\n",
    "Contribution statement\n",
    "* Part 1:\n",
    "* Part 2:\n",
    "* Part 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94df12c2",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495d0537",
   "metadata": {},
   "source": [
    "## Part 1: Mixing Patterns and Assortativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "872d397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import networkx as nx\n",
    "import netwulf as nw\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.colors as mcolors\n",
    "import math\n",
    "import statistics\n",
    "import random\n",
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f56e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the network\n",
    "G = nx.read_gpickle(\"css_graph.gpickle\")\n",
    "#Extarct the largets connected component from the network and save it as the new network\n",
    "components = list(nx.connected_components(G))\n",
    "largest_component = max(components, key=len)\n",
    "G = G.subgraph(largest_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91eb14c",
   "metadata": {},
   "source": [
    "* For each node, compute the fraction of edges that connect to a node that works in the same top field. Find the average value across all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83fe5840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make all missing top_fields = None\n",
    "for author in G.nodes:\n",
    "    if 'top_field' not in G.nodes[author]:\n",
    "        G.nodes[author]['top_field'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6f7201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network mean of the fraction of connections to authors in the same field is: 0.3918154061737561\n",
      "Here is a subset of the fractions of connections to authors in the same field\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('1759771', 0.55),\n",
       " ('1903596', 0),\n",
       " ('3456882', 0.42857142857142855),\n",
       " ('8554587', 0.125),\n",
       " ('36663090', 0.36363636363636365)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute average neighboors in same top field as each node\n",
    "def network_mean_same_field(top_fild_name):\n",
    "    for author in G.nodes:\n",
    "        G.nodes[author]['Avr_same_field'] = mean_same_field = statistics.mean(map(int, [G.nodes[author][top_fild_name] == field for field \n",
    "              in [G.nodes[neighboor][top_fild_name] for neighboor \n",
    "                  in G.neighbors(author)]]))\n",
    "    \n",
    "    #network average\n",
    "    network_mean = statistics.mean(map(float, [G.nodes[author]['Avr_same_field'] for author in G.nodes]))\n",
    "    return network_mean\n",
    "\n",
    "network_mean = network_mean_same_field('top_field')\n",
    "print('The network mean of the fraction of connections to authors in the same field is: ' + str(network_mean))\n",
    "print('Here is a subset of the fractions of connections to authors in the same field')\n",
    "list(nx.get_node_attributes(G, \"Avr_same_field\").items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cae803",
   "metadata": {},
   "source": [
    "* Repeat the point above 100 times (at least). Plot the distribution of the values obtained and compare it with the value you have found for the real graph. Is the chance to connect to a member of the same field significantly higher than it would be by chance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcce137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to randomise the top fields node assignments\n",
    "top_fields = list(nx.get_node_attributes(G, \"top_field\").values())\n",
    "def randomise_top_fields_rand():\n",
    "    random.shuffle(top_fields)\n",
    "    for i, author in enumerate(G.nodes):\n",
    "        G.nodes[author]['top_field_rand'] = top_fields[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54abb6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute average neighboors in same top field as each node 100 times for random top fields\n",
    "rand_means = []\n",
    "for i in range(100):\n",
    "    randomise_top_fields_rand()\n",
    "    rand_means.append(network_mean_same_field('top_field_rand'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f096e5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the null hypothesis that our network mean occured by random we get the following p-value\n",
      "p-value:3.7475434416479677e-122\n"
     ]
    }
   ],
   "source": [
    "#compute the p-value for the null-hypothesis that out network mean occured by random... The p-value is extreemly low\n",
    "t_stat, p_value = ttest_1samp(rand_means, network_mean)\n",
    "print(\"For the null hypothesis that our network mean occured by random we get the following p-value\")\n",
    "print('p-value:' + str(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea0268b",
   "metadata": {},
   "source": [
    "> The low p-value tells us that it is extremely unlikely that our high netwrok_mean has occured by random and we therefore conlcude that there is a relationsship between which field an author is working in and which field his neighboors (the authors he has written papers with) are in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661c2c4c",
   "metadata": {},
   "source": [
    "* Compute the assortativity coefficient with respect to author's field. How do you interpret the value you obtain? (Hint: See this paper, eq (2)). Important: here I do not want you to use the NetworkX implementation, but rather to implement your own version of the measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "097c1fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4e53ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def own_assortivity_measure(G, attribute):\n",
    "    #Compute average neighboors in same top field as each node 100 times for random top fields\n",
    "    rand_means = []\n",
    "    for i in range(100):\n",
    "        randomise_top_fields_rand()\n",
    "        rand_means.append(network_mean_same_field('top_field_rand'))\n",
    "    t_stat, p_value = ttest_1samp(rand_means, network_mean)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "56e4e615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.000e+00, 0.000e+00, 1.000e+01, 1.500e+01, 2.000e+00, 0.000e+00,\n",
       "        2.000e+00, 4.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        1.900e+01, 1.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 2.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 2.300e+01, 1.100e+01, 5.700e+01, 4.000e+00, 0.000e+00,\n",
       "        0.000e+00, 7.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00,\n",
       "        6.400e+01, 1.200e+01, 0.000e+00, 3.000e+00, 2.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [2.300e+01, 2.100e+01, 2.590e+02, 2.970e+02, 6.000e+00, 1.000e+00,\n",
       "        1.700e+01, 3.500e+01, 0.000e+00, 5.000e+00, 1.000e+00, 3.000e+00,\n",
       "        2.310e+02, 1.100e+01, 1.300e+01, 2.800e+01, 1.000e+00, 1.000e+00,\n",
       "        1.000e+01, 8.000e+00, 0.000e+00],\n",
       "       [2.100e+01, 1.070e+02, 4.110e+02, 1.260e+03, 5.900e+01, 1.100e+01,\n",
       "        3.800e+01, 1.150e+02, 6.000e+00, 1.100e+01, 3.000e+00, 1.000e+00,\n",
       "        1.026e+03, 1.140e+02, 1.600e+01, 4.900e+01, 1.600e+01, 6.000e+00,\n",
       "        6.000e+00, 2.400e+01, 6.000e+00],\n",
       "       [3.000e+00, 5.000e+00, 6.000e+00, 3.800e+01, 8.000e+00, 1.000e+00,\n",
       "        1.000e+00, 3.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        2.000e+01, 6.000e+00, 1.000e+00, 3.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 3.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, 5.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        2.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 2.000e+00, 7.000e+00, 1.300e+01, 0.000e+00, 0.000e+00,\n",
       "        4.000e+00, 4.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        9.000e+00, 2.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [1.000e+00, 7.000e+00, 3.200e+01, 9.600e+01, 4.000e+00, 3.000e+00,\n",
       "        1.200e+01, 9.600e+01, 0.000e+00, 0.000e+00, 1.000e+00, 2.000e+00,\n",
       "        7.300e+01, 6.000e+00, 4.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        1.000e+00, 2.000e+00, 0.000e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.000e+00, 3.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        3.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 3.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        5.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, 3.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        4.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        2.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [1.200e+01, 4.200e+01, 1.010e+02, 5.480e+02, 1.500e+01, 0.000e+00,\n",
       "        1.700e+01, 6.900e+01, 0.000e+00, 4.000e+00, 0.000e+00, 2.000e+00,\n",
       "        1.477e+03, 3.300e+01, 1.500e+01, 2.200e+01, 0.000e+00, 0.000e+00,\n",
       "        6.000e+00, 2.700e+01, 0.000e+00],\n",
       "       [0.000e+00, 8.000e+00, 1.600e+01, 6.700e+01, 9.000e+00, 2.000e+00,\n",
       "        1.000e+00, 4.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        6.000e+01, 2.200e+01, 0.000e+00, 5.000e+00, 3.000e+00, 0.000e+00,\n",
       "        0.000e+00, 4.000e+00, 0.000e+00],\n",
       "       [2.000e+00, 1.000e+00, 1.000e+01, 7.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 2.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        1.600e+01, 2.000e+00, 2.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 6.000e+00, 9.000e+00, 2.400e+01, 2.000e+00, 0.000e+00,\n",
       "        0.000e+00, 4.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        3.600e+01, 5.000e+00, 0.000e+00, 3.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, 7.000e+00, 3.000e+00, 1.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        8.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 2.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 2.000e+00, 1.100e+01, 5.000e+00, 2.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 0.000e+00,\n",
       "        4.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        2.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 4.000e+00, 1.700e+01, 1.000e+00, 0.000e+00,\n",
       "        2.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        2.400e+01, 1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 2.000e+00, 1.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 2.000e+00, 9.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assortivity_wrt_field(G, 'top_field')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c9b1b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18187918166360734"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assortativity_coefficient wrt. field\n",
    "nx.attribute_assortativity_coefficient(G, 'top_field')\n",
    "#The positive value of r indicates that authors with the same top field are more likely to connect to each other \n",
    "#than to authors with the same top fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "427386be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14104404760625552"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assortativity_coefficient wrt. degree (default)\n",
    "nx.degree_assortativity_coefficient(G)\n",
    "#The positive value of r mean s taht the network is aasortative wrt degree i.e. authors with similar degrees are more likely to connect to each other \n",
    "#than to authors with differetn degrees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7323219a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
